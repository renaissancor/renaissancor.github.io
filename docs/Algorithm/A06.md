# Bucket Sort 

Limit of Sort by Comparison 

Suppose sorting numbers a b c, having total 6 possibilities. 
It would be `abc` `acb` `bac` `bca` `cab` `cba`, total 6. 
It represents, Sorting probability exist total `n!`, permutation numbers. 
For total size of `n` array, there would exist total `n!` likelihoods of order. 

Comparison based sorting can be represented as binary decision tree. 
So, in perspective of binary decision tree, 
based on comparison result, it is likely to be a search tree of total 
`n!` number of leaf nodes. 

Suppose `n` numbers of elements to be sorted in a decision tree format, 
when drown as binary tree, there is total leaf node of `n!` numbers. 
Time complexity of this binary tree would be height of this tree. 
When there exists total `n!` numbers of leaf node, then the 
height can be measurable by `log (n!)`. 

**Stirling's Approximation**
Applied to thehe minumim height of the `n!` leaf nodes would be `log (n!)`. 

$$
n! \approx \sqrt{2\pi n} \left(\frac{n}{e}\right)^n
$$

$$
\log(n!) = \Theta(n \log n)
$$

Thus, worst caste of any sorting function based on one by one comparison and swap
will have at least $\Theta(n \log n)$. Or, since it is at least $\Theta(n \log n)$, 
meaning that it is $\Omega (n \log n)$

Then, any other way to make sorting faster, in linear time close to $O(n)$? 

## Counting Sort (계수 計數 정렬) 

All comparison sorts have at least $O(n \log n)$ time complexity as proven above. 

However, there are theoretically more faster ways to sort faster. 
Suppose we put balls in the basket. 
Memory access will be constant, $O(1)$. 

Prepare for basket for each number, considering that several numbers will be 
duplicated. Count how much each number exist and save in each different count array. 
Then, accumulate values from the end. 

Suppose `n` inputs and `k` numbers 

- Time  Complexity $\theta(n + k) = \theta(n)$
- Space Complexity $\theta(n + k) = \theta(n)$

## Radix Sort (기수 基數 정렬) 

It is tought to use counting sort to several digit numbers, 
since too large numbers will exponentially amplify complexity. 
For instance, if number unit is in 3 digits, array size should 
be $10^3 \eq 1000$. 

Thus, to maintain $O(1)$ close time complexity as much as possible 
while preventing too gigantic array is called as `Radix Sort`. 

Unconsciously people sort from high to low order, but it became 
divide and conquer rather than radix sort. 
So, in counting sort, it should be from lower digit to higher digit. 

Limits are, stable sort is required. 
Also, avoid unnecessary order changes. 
If current checking digit of two numbers are same, do NOT change order. 

Radix sort is stable sort, while Quick sort is unstable sort. 

In a counting sort, if maximum digit number is supposed as `d`, then
total time complexity will be 
$\Theta(d\dot(n+k)) = \Theta(n)$

## Bucket Sort 

Radix Sort exist for integers, but 
Bucket Sort can work for non integer numbers. 

Make appropriate size of the bucket array first and 
put similar sized numbers in order by division. 

After than, sort by simpler sort like insertion sort inside bucket. 

For instance, if input i is numbers between 0 ~ 1 and there exists 10 buckets, 
decide bucket by math formula like $float (i * 10) / 1$

$$
T(n) = \Theta(n) + \sigma^{n-1}_{i=0} O(n_i^2) \rightarrow T(n) = \Theta(n) 
$$

Ideal case, one number per one bucket, 
$n_i = 1 \rightarrow O(n_i^2) = O(1^2) = O(1)$

Worst, case, all numbers inside one single bucket 
$n_i = n \rightarrow O(n_i^2) = O(n^2)$

Average expectecd usage case, if small number `k` is input then 
$n_i = k \rightarrow O(n_i^2) = O(k^2) = O(1)$