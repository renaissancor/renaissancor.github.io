# Algorithms 

Path Finding 

## Recursion 

Basic recursion function works like this 

```cpp
void Recurse(unsigned int row, unsigned int col, char val)
{
    if(graph[row][col] == 0) return; 
    else if (graph[row][col] == val) return;
    else graph[row][col] = val;

    if (0 < col) Recurse(row, col - 1, val); 
    if (0 < row) Recurse(row - 1, col, val); 
    if (col < col_size - 1) Recurse(row, col + 1, val);
    if (row < row_size - 1) Recurse(row + 1, col, val); 
}
```

During the time measurement, the function is called a lot. 
For the simple DFS and BFS logic that do NOT check and mark value 
before it gets inside stack or queue, recursion is more efficient. 

Counting the function call, it is possible to figure out total function call count. 
Then, all functions including recursion, bfs, dfs have different function call count. 

This logic might be inefficient because sometimes same index of row and column value 
might get accessed several times. Moreover, wall values containing 0 might be 
accessed several times. Thus, the logic to prevent multiple access and condition check 
is required.  

It contains partially Memoization logic, which is one characteristic of Dynamic Programming. 
Since the code changes the previous data accessed, checking the value availability before 
calling recursion, or putting inside stack or queue would remove unnecessary function call 
or stack queue input. Thus, the following logic is required for all recursion, bfs, and dfs. 

```cpp 
if (col > 0 && graph[row][col - 1] != 0 && graph[row][col - 1] != val) Recurse(row, col - 1, val);
if (row > 0 && graph[row - 1][col] != 0 && graph[row - 1][col] != val) Recurse(row - 1, col, val);
if (col < col_size - 1 && graph[row][col + 1] != 0 && graph[row][col + 1] != val) Recurse(row, col + 1, val);
if (row < row_size - 1 && graph[row + 1][col] != 0 && graph[row + 1][col] != val) Recurse(row + 1, col, val);
```

Sounds messy and unnecessary, but this kind of condition check let the total function call, or 
total stack / queue input count same value, meaning that the optimal path is found despite of different 
approaches. 

## BFS (Breadth First Search)

Implementation based on Queue was approached with several methods, including 
dynamic memory allocation of independent rows and cols as unsigned integer, 
typedef struct with two unsigned intS, and using STLS including not only `std::vector` 
as an alternative of dynamic memory allocation, but also `std::queue`. 
Among these approaches, direct dynamic memory allocation of two arrays 
of `unsigned int` was the most efficient and fast in the testing process. 

```cpp 
unsigned int * qrow = new unsigned int [ROW_SIZE * COL_SIZE];
unsigned int * qcol = new unsigned int [ROW_SIZE * COL_SIZE]; 

vector<unsigned int> qrow(ROW_SIZE * COL_SIZE); 
vector<unsigned int> qcol(ROW_SIZE * COL_SIZE); 

queue<unsigned int> qrow;
queue<unsigned int> qcol;

struct RC{ unsigned int row; unsigned int col; } 
RC* queue = new RC[ROW_SIZE * COL_SIZE * 2];
std::vector<RC> queue; 
std::queue<RC> queue; 
```

Among all these, the most time efficient method was dynamic memory allocation of two arrays 
containing rows and columns for each, followed by `std::vector` instead of direct dynamic allocation 
with a slight difference. Since `std::queue` was quite inefficient due to the overhead caused 
by its basic `std::deque` based structure, it showed poor performance about more than twice time 
than using array and index of front and back. Also, struct based array and STL data structures 
clearly showed much lower performance than basic datatype based arrays like `unsigned int`. 
Thus, `RC` struct datatype was removed. 

```cpp
unsigned int* qrow = new unsigned int[ROW_SIZE * COL_SIZE];
unsigned int* qcol = new unsigned int[ROW_SIZE * COL_SIZE];
size_t front = 0, back = 0;
qrow[back] = row;
qcol[back] = col;
back++;

while (front < back)
{
    unsigned int row = qrow[front];
    unsigned int col = qcol[front];
    ++front;
    graph[row][col] = val; 

    if (col > 0 && graph[row][col - 1] != 0 && graph[row][col - 1] != val) {
        graph[row][col - 1] = val;
        qrow[back] = row;
        qcol[back] = col - 1;
        back++;
    } 
    // Same ... 
}
```

The original logic to input inside queue without checking availability worked 
more critically compared to DFS based on recursion or stack. 
Queue is FIFO, and without implementation of the circular queue logic structure, 
it would result in overflow, exceeding higher than the maximum queue size easily, 
even though it is set like `[ROW_SIZE * COL_SIZE * 5]`. 
Thus, especially for BFS that implement queue without circular structure, 
minimizing the queue input is necessary to avoid overflow. 

Since queue input without checking validity or visit of the value has potential to 
make so much input queue that buffer overflow of queue is very likely. 


## DFS (Depth First Search)

Implementation based on Stack was very similar to the array based Queue implementation 
written above. Similar to the BFS above, the time efficiency was similar, showing 
lower performance for using `std::stack` or struct datatype. 
Logic flow is very similar to the recursion, so unoptimized condition checking only 
edge value like `0 < col` applied for both recursion and dfs here gave same call counts. 

After the application of dynamic programming memoization to not visit already visited and 
unnecessary memory space, all BFS DFS and recursion function got same calls. However, still 
DFS has same logic with recursion, if direction comparison order is same.   

```cpp 
void Graph::DFS(unsigned int row, unsigned int col, char val)
{
    unsigned int *srow = new unsigned int[ROW_SIZE * COL_SIZE];
    unsigned int *scol = new unsigned int[ROW_SIZE * COL_SIZE]; 

    size_t top = 0;
    srow[top] = row; 
    scol[top] = col; 
    ++top; 

    while (top > 0)
    {
        cntjhp++;
        top--;
        UINT row = srow[top];
        UINT col = scol[top]; 

        graph[row][col] = val;

        if (0 < col && graph[row][col - 1] != 0 && graph[row][col - 1] != val) {
		    srow[top] = row;
		    scol[top] = col - 1;
		    ++top;
		    graph[row][col - 1] = val; // mark as visited
        }
        // Same logic ... 
    }
}
```

Only top index is required, unlike queue that requires both front and back. 

## Performance Analysis 

Now, after testing randomly generated maps, time measurement is required. 
Time testing was based on the modern C++ library `std::chrono`. 

```cpp 
std::chrono::steady_clock::time_point start, end;
long long duration;
start = steady_clock::now();
BFS(row, col, 2);
end = steady_clock::now();
duration = duration_cast<microseconds>(end - start).count(); 
time_record.bfs_time += duration;
```
By application of this structure, all execution time of function per second was measured. 

This is the original random map generated. 

```cpp
void Graph::CreateGraph() {
    srand((unsigned)time(nullptr));
    graph = new char* [row_size];
    for (unsigned int i = 0; i < row_size; ++i) {
        graph[i] = new char[col_size];
        for (unsigned int j = 0; j < col_size; ++j) {
            int r = rand() % 5; // 0~4
            if (i == 0) graph[i][j] = 1;
            else if (r == 4) graph[i][j] = 0; 
            else graph[i][j] = 1; 
        }
    }
}
```

This would result in huge random matrix with rows and columns. 
Occasionally some blocks might appear, but it is perfect to check spreading search environment. 
In this map, generally BFS showed slightly higher performance than DFS. 

```txt
Total Accumulated BFS   Time:    199831 μs
Total Accumulated BFSV  Time:    194558 μs
Total Accumulated BFSTL Time:    246616 μs
Total Accumulated DFS   Time:    201897 μs
Total Accumulated DFSV  Time:    210272 μs
Total Accumulated DFSTL Time:    458883 μs
Total Accumul Recursion Time:    214588 μs
Total Row Size: 50, Total Col Size: 220
Map Type: Random Graph, Iteration : 1000 
```


This result made probability that spreading style maps might favor BFS rather than DFS. 
However, for case of matrix with maze like structure, consequence might be different. 
Thus, the Maze like maps was implemented instead, to make sure one line is full and one line 
is blocked with only one single available element per each row.

```cpp
void Graph::CreateMaze() {
    srand((unsigned)time(nullptr));
    graph = new char* [row_size];
    for (unsigned int i = 0; i < row_size; ++i) {
        graph[i] = new char[col_size];
		int r = rand() % col_size; // 0~4
        for (unsigned int j = 0; j < col_size; ++j) {
            if (i % 2 == 0) graph[i][j] = 1; 
            else if (j == r) graph[i][j] = 1; 
			else graph[i][j] = 0; 
        }
    }
}
```

This case, DFS gave slightly, but meaningfully more higher than BFS, showing that 
sometimes DFS might be more efficient than BFS in a maze or path like matrix, 
while BFS is more efficient than DFS in wide, spreading matrix.  

```txt
Total Accumulated BFS   Time:     29929 μs
Total Accumulated BFSV  Time:     34815 μs
Total Accumulated BFSTL Time:    101968 μs
Total Accumulated DFS   Time:     28094 μs
Total Accumulated DFSV  Time:     32001 μs
Total Accumulated DFSTL Time:     87057 μs
Total Accumul Recursion Time:     42940 μs
Total Row Size: 50, Total Col Size: 220
Map Type: Maze,         Iteration : 1000 
```

Also, result showed that highly optimized BFS and DFS by using most fundamental 
form of dynamic array allocation with index to use them as stack and queue is enough 
to accomplish higher performance than the recursion function. 


| Algorithm      | Random Map (μs) | Maze Map (μs) | Random Map (%) | Maze Map (%) |
| -------------- | --------------- | ------------- | -------------- | ------------ |
| **BFS**        | 199831          | 29929         | **100%**       | 106.5%       |
| **DFS**        | 201897          | 28094         | 101.0%         | **100%**     |
| **Recursion**  | 214588          | 42940         | 107.4%         | 152.8%       |
| **std::queue** | 246616          | 101968        | 123.4%         | 362.8%       |
| **std::stack** | 458883          | 87057         | 229.6%         | 309.9%       |

In conclusion, for map of about 50 X 220 size, the test result was following. 

